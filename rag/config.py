"""
Конфигурация RAG-системы.
Все настройки в одном месте — легко менять модель, адрес Qdrant и параметры.
"""

import os
from pathlib import Path
from dotenv import load_dotenv

load_dotenv(Path(__file__).resolve().parent.parent / ".env")

# ── Пути ─────────────────────────────────────────────────────────────
PROJECT_ROOT = Path(__file__).resolve().parent.parent
DATA_DIR = PROJECT_ROOT / "data"
CHUNKS_PATH = DATA_DIR / "chunks" / "chunks.json"
DOC_TEXTS_PATH = DATA_DIR / "chunks" / "doc_texts.json"

# ── Модель эмбеддингов ──────────────────────────────────────────────
EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
EMBEDDING_DIMENSION = 384  # размер вектора для этой модели

# ── Qdrant ───────────────────────────────────────────────────────────
QDRANT_HOST = "localhost"
QDRANT_PORT = 6333
COLLECTION_NAME = "department_chunks"

# ── Чанковка ─────────────────────────────────────────────────────────
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50

# ── Retriever ────────────────────────────────────────────────────────
TOP_K = 5  # сколько документов (страниц) возвращать при поиске
SEMANTIC_TOP_K = 15  # сколько чанков брать из семантического поиска (до дедупликации)
KEYWORD_TOP_K = 10  # сколько чанков брать из keyword-поиска

# ── LLM (OpenRouter) ────────────────────────────────────────────────
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "")
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
LLM_MODEL = "stepfun/step-3.5-flash:free"
LLM_TEMPERATURE = 0.3
LLM_MAX_TOKENS = 2048

SYSTEM_PROMPT = """\
Ты — интеллектуальный помощник кафедры аэрогидромеханики КФУ.
Твоя задача — отвечать на вопросы пользователей, используя ТОЛЬКО предоставленный контекст.

Правила:
1. Отвечай точно и по существу, основываясь на контексте.
2. Если в контексте нет информации для ответа — честно скажи об этом.
3. Указывай источники (URL страниц), откуда взята информация.
4. Отвечай на русском языке.
5. Будь вежлив и помогай пользователям разобраться в информации о кафедре.
"""
